/**
 * TTS Service - Text-to-Speech v·ªõi ƒëa nh√† cung c·∫•p
 *
 * @description H·ªó tr·ª£ Google TTS (mi·ªÖn ph√≠) v√† OpenAI TTS (c√≥ ph√≠, ch·∫•t l∆∞·ª£ng cao)
 * @usage ƒê∆∞·ª£c s·ª≠ d·ª•ng b·ªüi route /api/tts
 *
 * Providers:
 * - Google TTS: Mi·ªÖn ph√≠, s·ª≠ d·ª•ng node-gtts
 * - OpenAI TTS: $0.015/1000 chars, s·ª≠ d·ª•ng openai SDK v·ªõi models tts-1/tts-1-hd
 */

// @ts-ignore - node-gtts kh√¥ng c√≥ type declarations
import gTTS from 'node-gtts';
import OpenAI from 'openai';
import { TextToSpeechClient, protos } from '@google-cloud/text-to-speech';
import { promises as fs } from 'fs';
import path from 'path';
import { v4 as uuidv4 } from 'uuid';
import { normalizeText } from '@tts-telegram/shared/TextNormalizationService.js';

// ============================================
// TYPES
// ============================================

export type TTSProvider = 'google' | 'openai' | 'google-cloud';

export interface TTSVoice {
  id: string;
  name: string;
  shortName: string;
  gender: 'Male' | 'Female' | 'Neutral';
  locale: string;
  description?: string;
  provider: TTSProvider;
}

export interface TTSSynthesizeRequest {
  text: string;
  provider?: TTSProvider;
  voice?: string;
  randomVoice?: boolean;
  rate?: number;
  volume?: number;
  pitch?: number;
}

export interface TTSSynthesizeResponse {
  id: string;
  audioUrl: string;
  duration: number;
  text: string;
  voiceUsed?: string;
  providerUsed?: TTSProvider;
}

// ============================================
// CONSTANTS
// ============================================

const AUDIO_CACHE_DIR = path.join(process.cwd(), 'audio-cache');

/**
 * Danh s√°ch gi·ªçng Google TTS
 */
const GOOGLE_VOICES: TTSVoice[] = [
  {
    id: 'vi',
    name: 'Ti·∫øng Vi·ªát',
    shortName: 'vi',
    gender: 'Female',
    locale: 'vi-VN',
    description: 'Gi·ªçng n·ªØ ti·∫øng Vi·ªát chu·∫©n',
    provider: 'google',
  },
  {
    id: 'en-us',
    name: 'English (US)',
    shortName: 'en-us',
    gender: 'Female',
    locale: 'en-US',
    description: 'Gi·ªçng M·ªπ',
    provider: 'google',
  },
  {
    id: 'en-uk',
    name: 'English (UK)',
    shortName: 'en-uk',
    gender: 'Female',
    locale: 'en-GB',
    description: 'Gi·ªçng Anh',
    provider: 'google',
  },
  {
    id: 'en-au',
    name: 'English (Australia)',
    shortName: 'en-au',
    gender: 'Female',
    locale: 'en-AU',
    description: 'Gi·ªçng √öc',
    provider: 'google',
  },
];

/**
 * Danh s√°ch gi·ªçng OpenAI TTS
 * H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ (bao g·ªìm ti·∫øng Vi·ªát)
 */
const OPENAI_VOICES: TTSVoice[] = [
  {
    id: 'alloy',
    name: 'Alloy',
    shortName: 'alloy',
    gender: 'Neutral',
    locale: 'multi',
    description: 'C√¢n b·∫±ng, trung t√≠nh',
    provider: 'openai',
  },
  {
    id: 'echo',
    name: 'Echo',
    shortName: 'echo',
    gender: 'Male',
    locale: 'multi',
    description: '·∫§m √°p, tr·∫ßm',
    provider: 'openai',
  },
  {
    id: 'fable',
    name: 'Fable',
    shortName: 'fable',
    gender: 'Neutral',
    locale: 'multi',
    description: 'Bi·ªÉu c·∫£m, British',
    provider: 'openai',
  },
  {
    id: 'onyx',
    name: 'Onyx',
    shortName: 'onyx',
    gender: 'Male',
    locale: 'multi',
    description: 'S√¢u, quy·ªÅn l·ª±c',
    provider: 'openai',
  },
  {
    id: 'nova',
    name: 'Nova',
    shortName: 'nova',
    gender: 'Female',
    locale: 'multi',
    description: 'Th√¢n thi·ªán, n·ªØ t√≠nh',
    provider: 'openai',
  },
  {
    id: 'shimmer',
    name: 'Shimmer',
    shortName: 'shimmer',
    gender: 'Female',
    locale: 'multi',
    description: 'R√µ r√†ng, l·∫°c quan',
    provider: 'openai',
  },
];

/**
 * Danh s√°ch gi·ªçng Google Cloud TTS ti·∫øng Vi·ªát
 * Bao g·ªìm Neural2, WaveNet v√† Standard
 * Chi ph√≠: Neural2 ~$16/1M chars, WaveNet ~$16/1M chars, Standard ~$4/1M chars
 */
const GOOGLE_CLOUD_VOICES: TTSVoice[] = [
  // Neural2 - Ch·∫•t l∆∞·ª£ng cao nh·∫•t
  {
    id: 'vi-VN-Neural2-A',
    name: 'Neural2 N·ªØ A',
    shortName: 'vi-VN-Neural2-A',
    gender: 'Female',
    locale: 'vi-VN',
    description: '‚≠ê Ch·∫•t l∆∞·ª£ng cao, t·ª± nhi√™n',
    provider: 'google-cloud',
  },
  {
    id: 'vi-VN-Neural2-D',
    name: 'Neural2 Nam D',
    shortName: 'vi-VN-Neural2-D',
    gender: 'Male',
    locale: 'vi-VN',
    description: '‚≠ê Ch·∫•t l∆∞·ª£ng cao, t·ª± nhi√™n',
    provider: 'google-cloud',
  },
  // WaveNet - Ch·∫•t l∆∞·ª£ng cao
  {
    id: 'vi-VN-Wavenet-A',
    name: 'WaveNet N·ªØ A',
    shortName: 'vi-VN-Wavenet-A',
    gender: 'Female',
    locale: 'vi-VN',
    description: 'Gi·ªçng n·ªØ, m·ªÅm m·∫°i',
    provider: 'google-cloud',
  },
  {
    id: 'vi-VN-Wavenet-B',
    name: 'WaveNet Nam B',
    shortName: 'vi-VN-Wavenet-B',
    gender: 'Male',
    locale: 'vi-VN',
    description: 'Gi·ªçng nam, tr·∫ßm ·∫•m',
    provider: 'google-cloud',
  },
  {
    id: 'vi-VN-Wavenet-C',
    name: 'WaveNet N·ªØ C',
    shortName: 'vi-VN-Wavenet-C',
    gender: 'Female',
    locale: 'vi-VN',
    description: 'Gi·ªçng n·ªØ, trong tr·∫ªo',
    provider: 'google-cloud',
  },
  {
    id: 'vi-VN-Wavenet-D',
    name: 'WaveNet Nam D',
    shortName: 'vi-VN-Wavenet-D',
    gender: 'Male',
    locale: 'vi-VN',
    description: 'Gi·ªçng nam, r√µ r√†ng',
    provider: 'google-cloud',
  },
  // Standard - Mi·ªÖn ph√≠ tier
  {
    id: 'vi-VN-Standard-A',
    name: 'Standard N·ªØ A',
    shortName: 'vi-VN-Standard-A',
    gender: 'Female',
    locale: 'vi-VN',
    description: 'Gi·ªçng c∆° b·∫£n, ti·∫øt ki·ªám',
    provider: 'google-cloud',
  },
  {
    id: 'vi-VN-Standard-B',
    name: 'Standard Nam B',
    shortName: 'vi-VN-Standard-B',
    gender: 'Male',
    locale: 'vi-VN',
    description: 'Gi·ªçng c∆° b·∫£n, ti·∫øt ki·ªám',
    provider: 'google-cloud',
  },
  {
    id: 'vi-VN-Standard-C',
    name: 'Standard N·ªØ C',
    shortName: 'vi-VN-Standard-C',
    gender: 'Female',
    locale: 'vi-VN',
    description: 'Gi·ªçng c∆° b·∫£n, ti·∫øt ki·ªám',
    provider: 'google-cloud',
  },
  {
    id: 'vi-VN-Standard-D',
    name: 'Standard Nam D',
    shortName: 'vi-VN-Standard-D',
    gender: 'Male',
    locale: 'vi-VN',
    description: 'Gi·ªçng c∆° b·∫£n, ti·∫øt ki·ªám',
    provider: 'google-cloud',
  },
];

// ============================================
// TTS SERVICE
// ============================================

class TTSService {
  private openaiClient: OpenAI | null = null;
  private googleCloudClient: TextToSpeechClient | null = null;
  private defaultProvider: TTSProvider = 'google';
  private defaultGoogleVoice = 'vi';
  private defaultOpenAIVoice = 'nova';
  private defaultGoogleCloudVoice = 'vi-VN-Neural2-A';

  constructor() {
    this.ensureCacheDir();
    this.initOpenAI();
    this.initGoogleCloud();
  }

  /**
   * Kh·ªüi t·∫°o OpenAI client n·∫øu c√≥ API key
   */
  private initOpenAI(): void {
    const apiKey = process.env.OPENAI_API_KEY;
    if (apiKey) {
      this.openaiClient = new OpenAI({ apiKey });
      console.log('‚úÖ TTS: OpenAI ƒë√£ kh·ªüi t·∫°o');
    } else {
      console.log('‚ö†Ô∏è TTS: Kh√¥ng c√≥ OPENAI_API_KEY - OpenAI TTS b·ªã t·∫Øt');
    }
  }

  /**
   * Kh·ªüi t·∫°o Google Cloud TTS client n·∫øu c√≥ API key
   */
  private initGoogleCloud(): void {
    const apiKey = process.env.GOOGLE_CLOUD_API_KEY;
    if (apiKey) {
      // S·ª≠ d·ª•ng API key ƒë·ªÉ kh·ªüi t·∫°o client
      this.googleCloudClient = new TextToSpeechClient({
        apiKey: apiKey,
      });
      console.log('‚úÖ TTS: Google Cloud ƒë√£ kh·ªüi t·∫°o');
    } else {
      console.log('‚ö†Ô∏è TTS: Kh√¥ng c√≥ GOOGLE_CLOUD_API_KEY - Google Cloud TTS b·ªã t·∫Øt');
    }
  }

  /**
   * ƒê·∫£m b·∫£o th∆∞ m·ª•c cache t·ªìn t·∫°i
   */
  private async ensureCacheDir(): Promise<void> {
    try {
      await fs.mkdir(AUDIO_CACHE_DIR, { recursive: true });
      console.log('üìÅ TTS: Cache:', AUDIO_CACHE_DIR);
    } catch (error) {
      console.error('‚ùå TTS: Kh√¥ng th·ªÉ t·∫°o cache dir:', error);
    }
  }

  /**
   * L·∫•y danh s√°ch voices theo provider
   */
  getVoicesByProvider(provider: TTSProvider): TTSVoice[] {
    switch (provider) {
      case 'openai':
        return OPENAI_VOICES;
      case 'google-cloud':
        return GOOGLE_CLOUD_VOICES;
      default:
        return GOOGLE_VOICES;
    }
  }

  /**
   * L·∫•y t·∫•t c·∫£ voices
   */
  getAllVoices(): TTSVoice[] {
    return [
      ...GOOGLE_VOICES,
      ...(this.openaiClient ? OPENAI_VOICES : []),
      ...(this.googleCloudClient ? GOOGLE_CLOUD_VOICES : []),
    ];
  }

  /**
   * Ki·ªÉm tra Google Cloud c√≥ kh·∫£ d·ª•ng kh√¥ng
   */
  isGoogleCloudAvailable(): boolean {
    return this.googleCloudClient !== null;
  }

  /**
   * L·∫•y voices ti·∫øng Vi·ªát (t∆∞∆°ng th√≠ch c≈©)
   */
  getVietnameseVoices(): TTSVoice[] {
    return GOOGLE_VOICES.filter((v) => v.locale.startsWith('vi'));
  }

  /**
   * Ki·ªÉm tra OpenAI c√≥ kh·∫£ d·ª•ng kh√¥ng
   */
  isOpenAIAvailable(): boolean {
    return this.openaiClient !== null;
  }

  /**
   * Ch·ªçn voice ng·∫´u nhi√™n
   */
  getRandomVoice(provider: TTSProvider): TTSVoice {
    const voices = this.getVoicesByProvider(provider);
    const index = Math.floor(Math.random() * voices.length);
    return voices[index];
  }

  /**
   * Synthesize v·ªõi Google TTS
   */
  private async synthesizeWithGoogle(
    text: string,
    voice: string,
    id: string,
    filepath: string
  ): Promise<void> {
    const gtts = gTTS(voice);
    await new Promise<void>((resolve, reject) => {
      gtts.save(filepath, text, (err?: Error) => {
        if (err) reject(err);
        else resolve();
      });
    });
  }

  /**
   * Synthesize v·ªõi OpenAI TTS
   */
  private async synthesizeWithOpenAI(
    text: string,
    voice: string,
    id: string,
    filepath: string
  ): Promise<void> {
    if (!this.openaiClient) {
      throw new Error('OpenAI TTS kh√¥ng kh·∫£ d·ª•ng - thi·∫øu API key');
    }

    const response = await this.openaiClient.audio.speech.create({
      model: 'tts-1',
      voice: voice as 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer',
      input: text,
    });

    const buffer = Buffer.from(await response.arrayBuffer());
    await fs.writeFile(filepath, buffer);
  }

  /**
   * Synthesize v·ªõi Google Cloud TTS
   * 
   * @description S·ª≠ d·ª•ng Google Cloud Text-to-Speech API v·ªõi Neural2/WaveNet/Standard voices
   * @param text - VƒÉn b·∫£n c·∫ßn synthesize  
   * @param voice - T√™n voice (v√≠ d·ª•: vi-VN-Neural2-A)
   * @param id - ID duy nh·∫•t c·ªßa audio
   * @param filepath - ƒê∆∞·ªùng d·∫´n l∆∞u file audio
   */
  private async synthesizeWithGoogleCloud(
    text: string,
    voice: string,
    id: string,
    filepath: string
  ): Promise<void> {
    if (!this.googleCloudClient) {
      throw new Error('Google Cloud TTS kh√¥ng kh·∫£ d·ª•ng - thi·∫øu API key');
    }

    // T·∫°o request cho Google Cloud TTS
    const request: protos.google.cloud.texttospeech.v1.ISynthesizeSpeechRequest = {
      input: { text },
      voice: {
        languageCode: 'vi-VN',
        name: voice,
      },
      audioConfig: {
        audioEncoding: protos.google.cloud.texttospeech.v1.AudioEncoding.MP3,
      },
    };

    // G·ªçi API
    const [response] = await this.googleCloudClient.synthesizeSpeech(request);

    if (!response.audioContent) {
      throw new Error('Kh√¥ng nh·∫≠n ƒë∆∞·ª£c audio t·ª´ Google Cloud TTS');
    }

    // L∆∞u file
    await fs.writeFile(filepath, response.audioContent as Buffer);
  }

  /**
   * T·∫°o audio t·ª´ text
   *
   * @param request - Y√™u c·∫ßu synthesize v·ªõi provider, voice, randomVoice
   * @returns Promise<TTSSynthesizeResponse>
   */
  async synthesize(request: TTSSynthesizeRequest): Promise<TTSSynthesizeResponse> {
    const { text, randomVoice = false } = request;
    let provider = request.provider || this.defaultProvider;
    let voice = request.voice;

    if (!text || text.trim().length === 0) {
      throw new Error('Text kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng');
    }

    // ‚ú® Chu·∫©n h√≥a text: teencode/slang -> formal Vietnamese
    // V√≠ d·ª•: "ko ƒëc cm" -> "kh√¥ng ƒë∆∞·ª£c ch√∫ng m√†y"
    const normalizedText = normalizeText(text, {
      normalizeTeencode: true,
      filterProfanity: true, // Replace t·ª´ kh√¥ng ph√π h·ª£p b·∫±ng placeholder
    });
    
    // Log n·∫øu c√≥ thay ƒë·ªïi
    if (normalizedText !== text) {
      console.log(`üìù TTS: Normalized text`);
      console.log(`   Original: "${text.substring(0, 100)}${text.length > 100 ? '...' : ''}"`);
      console.log(`   Normalized: "${normalizedText.substring(0, 100)}${normalizedText.length > 100 ? '...' : ''}"`);
    }

    // Fallback n·∫øu OpenAI kh√¥ng kh·∫£ d·ª•ng
    if (provider === 'openai' && !this.openaiClient) {
      console.log('‚ö†Ô∏è TTS: Fallback t·ª´ OpenAI sang Google');
      provider = 'google';
    }

    // Fallback n·∫øu Google Cloud kh√¥ng kh·∫£ d·ª•ng
    if (provider === 'google-cloud' && !this.googleCloudClient) {
      console.log('‚ö†Ô∏è TTS: Fallback t·ª´ Google Cloud sang Google (mi·ªÖn ph√≠)');
      provider = 'google';
    }

    // Random voice n·∫øu ƒë∆∞·ª£c b·∫≠t
    if (randomVoice) {
      const randomVoiceObj = this.getRandomVoice(provider);
      voice = randomVoiceObj.shortName;
      console.log(`üé≤ TTS: Random voice: ${randomVoiceObj.name} (${provider})`);
    }

    // Default voice theo provider
    if (!voice) {
      switch (provider) {
        case 'openai':
          voice = this.defaultOpenAIVoice;
          break;
        case 'google-cloud':
          voice = this.defaultGoogleCloudVoice;
          break;
        default:
          voice = this.defaultGoogleVoice;
      }
    }

    // Gi·ªõi h·∫°n text (s·ª≠ d·ª•ng normalizedText thay v√¨ text g·ªëc)
    const maxLength = 5000;
    const truncatedText = normalizedText.length > maxLength ? normalizedText.substring(0, maxLength) + '...' : normalizedText;

    const id = uuidv4();
    const filename = `${id}.mp3`;
    const filepath = path.join(AUDIO_CACHE_DIR, filename);

    try {
      console.log(`üîä TTS: Synthesizing v·ªõi ${provider}, voice: ${voice}`);

      if (provider === 'openai') {
        await this.synthesizeWithOpenAI(truncatedText, voice, id, filepath);
      } else if (provider === 'google-cloud') {
        await this.synthesizeWithGoogleCloud(truncatedText, voice, id, filepath);
      } else {
        await this.synthesizeWithGoogle(truncatedText, voice, id, filepath);
      }

      // ∆Ø·ªõc t√≠nh duration
      const wordCount = truncatedText.split(/\s+/).length;
      const estimatedDuration = Math.max(1, Math.ceil((wordCount / 150) * 60));

      console.log(`‚úÖ TTS: ${filename} (${provider}/${voice}, ${wordCount} t·ª´)`);

      return {
        id,
        audioUrl: `/api/tts/stream/${id}`,
        duration: estimatedDuration,
        text: truncatedText,
        voiceUsed: voice,
        providerUsed: provider,
      };
    } catch (error) {
      console.error('‚ùå TTS: L·ªói synthesize:', error);
      throw new Error(`Kh√¥ng th·ªÉ t·∫°o audio: ${error instanceof Error ? error.message : 'Unknown'}`);
    }
  }

  /**
   * L·∫•y ƒë∆∞·ªùng d·∫´n file audio
   */
  async getAudioPath(id: string): Promise<string | null> {
    const filepath = path.join(AUDIO_CACHE_DIR, `${id}.mp3`);
    try {
      await fs.access(filepath);
      return filepath;
    } catch {
      return null;
    }
  }

  /**
   * X√≥a audio ƒë√£ t·∫°o
   */
  async deleteAudio(id: string): Promise<void> {
    const filepath = path.join(AUDIO_CACHE_DIR, `${id}.mp3`);
    try {
      await fs.unlink(filepath);
      console.log(`üóëÔ∏è TTS: ƒê√£ x√≥a ${id}.mp3`);
    } catch {
      // Ignore
    }
  }

  /**
   * X√≥a t·∫•t c·∫£ cache
   */
  async clearCache(): Promise<void> {
    try {
      const files = await fs.readdir(AUDIO_CACHE_DIR);
      for (const file of files) {
        if (file.endsWith('.mp3')) {
          await fs.unlink(path.join(AUDIO_CACHE_DIR, file));
        }
      }
      console.log(`üßπ TTS: ƒê√£ x√≥a ${files.length} files`);
    } catch (error) {
      console.error('‚ùå TTS: L·ªói x√≥a cache:', error);
    }
  }
}

export const ttsService = new TTSService();
